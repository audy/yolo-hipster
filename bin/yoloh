#!/usr/bin/env python

import logging
from collections import defaultdict

import click
import pandas as pd


from skbio.parse.sequences import parse_fasta

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import HashingVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder


@click.group()
def cli():
    pass


@click.command()
@click.option('--training-sequences', help='training sequences. hint: use greengenes.')
@click.option('--query-sequences', help='query sequences in fasta format')
@click.option('--taxonomies', help='training taxonomies. hint: use greengenes.')
@click.option('--output', help='where to save trained model.')
@click.option('--rank', help='taxonomic rank to train at', default='Species')
@click.option('--ngram-range', nargs = 2, type=int, default=(4, 4))
def classify(*args, **kwargs):

    print kwargs

    # load taxonomies into pandas DataFrame
    # for convenience, we're gonna store sequences and labels in
    # this dataframe as well.
    logging.info('reading taxonomies from %s' % kwargs['taxonomies'])
    tax_table = pd.read_csv(kwargs['taxonomies'], dtype=str, index_col=0)
    logging.info('loaded %s taxonomic descriptions' % len(tax_table))

    # load sequences
    logging.info('reading sequences from %s' % kwargs['training_sequences'])
    with open(kwargs['training_sequences']) as handle:
        seqs = list(parse_fasta(handle))
    logging.info('loaded %s training sequences' % len(seqs))

    # train
    tax_table = tax_table.dropna()
    logging.info('kept %s taxonomic descriptions' % len(tax_table))

    # 1. keep only sequences with valid classification at rank
    # 2. convert to dictionary id -> sequence
    keep_ids = set(str(i) for i in tax_table.index)
    seqs = { r[0]: r[1] for r in seqs if r[0] in keep_ids }
    logging.info('kept %s training sequences' % len(seqs))

    tax_table = tax_table.ix[seqs.keys()]

    # put sequences in tax_table
    tax_table.sequence = [ seqs[i] for i in tax_table.index ]

    logging.info('have %s different labels' % len(set(tax_table['Species'])))

    logging.info('classifying at %s rank' % kwargs['rank'])

    # transform labels
    label_encoder = LabelEncoder()
    logging.info('transforming labels using %s' % label_encoder)
    tax_table.label = label_encoder.fit_transform(tax_table[kwargs['rank']])

    # define transformation and classification pipeline
    hasher = HashingVectorizer(analyzer='char',
                               ngram_range=kwargs['ngram_range'],
                               non_negative=True)

    classifier = MultinomialNB()

    pipeline = Pipeline([('transformer', hasher),
                         ('classifier', classifier)])

    # fit the classifier
    logging.info('fitting classifier')

    pipeline.fit(tax_table.sequence, tax_table.label)

    # iterate over query sequences, predicting probabilites for each
    # store probabilities in a matrix (DataFrame) with database ID
    # as the column and sequence ID as the row

    target_record_proba = defaultdict(dict)

    with open(kwargs['query_sequences']) as handle:
        records = parse_fasta(handle)

        for record in records:
            probs = pipeline.predict_proba([record[1]])
            for t, p in zip(tax_table[kwargs['rank']], probs[0]):
                target_record_proba[t][record[0]] = p

    results = pd.DataFrame.from_dict(target_record_proba)

    logging.info('writing to %s' % kwargs['output'])
    results.to_csv(kwargs['output'])

    logging.info('done! have a nice day!')



if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, logfile='/dev/stderr')
    cli.add_command(classify)
    cli()
